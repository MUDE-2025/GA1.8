{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1f4a43-d5f0-4330-8cba-6124e726ac6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Group Assignment 1.8: Fit (and test) me baby, one more time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74831704",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Focus: GNSS Observations\n",
    "In the previous assignment, you collected and analyzed height data from two different techniques: Global Navigation Satellite Systems (GNSS) and Interferometric Synthetic-aperture radar (InSAR).\n",
    "For this continuation assignment, we will focus exclusively on the GNSS height observations. This involves using the time series data provided in the file `gnss_observations.csv`, which lists observed vertical displacements (in meters). You will not be using the InSAR data in this week's assignment.\n",
    "\n",
    "Stochastic Model of Observations\n",
    "Consistent with the previous assignment, the GNSS observations are characterized by the following stochastic properties:\n",
    "- They are normally distributed and independent.\n",
    "\n",
    "- They have a known standard deviation $\\sigma_\\textrm{GNSS} = 15$ mm \n",
    "\n",
    "### Assignment Theme: Non-Linear Functional Models\n",
    "The core focus of this week's work is the estimation of parameters using non-linear functional models. You will explore the techniques required to solve these models, including estimating the parameters and assessing the precision of the estimates, and conducting rigorous statistical evaluations using methods like the overall model test (OMT) and the generalized likelihood ratio test (GLRT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ccfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.distributions import chi2\n",
    "from scipy.stats import norm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def findfile(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        print(f\"Downloading {fname}...\")\n",
    "        urlretrieve('http://files.mude.citg.tudelft.nl/'+fname, fname)\n",
    "\n",
    "findfile('gnss_observations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d6250",
   "metadata": {
    "id": "160d6250"
   },
   "source": [
    "## Part 1: Preparing the data and code from last week's assignment\n",
    "\n",
    "As mentioned, this assignment focuses on only the GNSS observations. Here the data is loaded. Make sure to add your own code where needed. You should have done this already in last week's assignment. The BLUE function (`BLUE`) and functions for plotting the residuals (`plot_residuals`)  are copied here from last week's assignment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnss = pd.read_csv('./gnss_observations.csv')\n",
    "gnss_dates = pd.to_datetime(gnss['Dates'])\n",
    "gnss_doy = (gnss['Day of Year']).to_numpy()\n",
    "gnss_obs = (gnss['Observations[m]']).to_numpy()\n",
    "\n",
    "m_gnss = len(gnss_obs)\n",
    "y_gnss = gnss_obs\n",
    "std_gnss = 0.015 #m\n",
    "Sigma_Y_gnss = np.identity(len(gnss_dates))*std_gnss**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLUE(A, y, Sigma_Y):\n",
    "    \"\"\"Calculate the Best Linear Unbiased Estimator\n",
    "    \n",
    "    Write a docstring here (an explanation of your function).\n",
    "    \n",
    "    Function to calculate the Best Linear Unbiased Estimator\n",
    "    \n",
    "    Input:\n",
    "        A = A matrix (mxn)\n",
    "        y = vector with observations (mx1)\n",
    "        Sigma_Y = variance-covariance matrix of the observations (mxm)\n",
    "    \n",
    "    Output:\n",
    "        xhat = vector with the estimates (nx1)\n",
    "        Sigma_Xhat = variance-covariance matrix of the unknown parameters (nxn)\n",
    "    \"\"\"\n",
    "    \n",
    "    Sigma_Xhat = np.linalg.inv(A.T @ np.linalg.inv(Sigma_Y) @ A)\n",
    "    xhat = Sigma_Xhat @ A.T @ np.linalg.inv(Sigma_Y) @ y\n",
    "    \n",
    "    return xhat, Sigma_Xhat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual(date, y_obs, yhat, data_type, A,\n",
    "                  Sigma_Xhat, Sigma_Y):\n",
    "\n",
    "    ehat = y_obs - yhat\n",
    "\n",
    "    # Compute the vc matrix for \\hat{y}\n",
    "    Sigma_Yhat = A @ Sigma_Xhat @ A.T\n",
    "    std_y = np.sqrt(Sigma_Yhat.diagonal())\n",
    "\n",
    "    # Compute the vc matrix for \\hat{e}\n",
    "    Sigma_ehat = Sigma_Y - Sigma_Yhat\n",
    "    std_ehat = np.sqrt(Sigma_ehat.diagonal())\n",
    "    \n",
    "    # Compute residuals normalized by standard deviation\n",
    "    ehat_normalized = ehat / std_ehat\n",
    "\n",
    "    # Show the 99% confidence interval\n",
    "    k99 = norm.ppf(1 - 0.5*0.01)\n",
    "    confidence_interval_y = k99*std_y\n",
    "    confidence_interval_res = k99*std_ehat\n",
    "\n",
    "    # Plot original data and fitted model\n",
    "    plt.figure(figsize = (15,5))\n",
    "    plt.plot(date, y_obs, 'k+',  label = 'Observations')\n",
    "    plt.plot(date, yhat,  label = 'Fitted model')\n",
    "    plt.fill_between(date, (yhat - confidence_interval_y), \n",
    "                     (yhat + confidence_interval_y), facecolor='orange',\n",
    "                     alpha=0.4, label = '99% Confidence Region')\n",
    "    plt.legend()\n",
    "    plt.ylabel(data_type + ' Displacement [m]')\n",
    "    plt.xlabel('Time')\n",
    "    plt.title(data_type + ' Observations and Fitted Model')\n",
    "\n",
    "\n",
    "    # Plot time series of the residual\n",
    "    plt.figure(figsize = (15,5))\n",
    "    plt.plot(date, ehat, 'o', markeredgecolor='black', label='Residual')\n",
    "    plt.plot(date,-confidence_interval_res, '--', color='orange', \n",
    "             label = '99% Confidence Region')\n",
    "    plt.plot(date,confidence_interval_res, '--', color='orange')\n",
    "    plt.legend()\n",
    "    plt.ylabel(data_type + ' residual [m]')\n",
    "    plt.xlabel('Time')\n",
    "    plt.title(data_type + ' Residuals')\n",
    "\n",
    "    # Plot histogram and normal distribution\n",
    "    plt.figure(figsize = (12,5))\n",
    "    plt.subplot(121)\n",
    "    plt.hist(ehat_normalized, bins = 40, density=True,  edgecolor='black')\n",
    "    x = np.linspace(np.min(ehat_normalized), np.max(ehat_normalized), num=100);\n",
    "    plt.plot(x, norm.pdf(x, loc=0.0, scale = 1),\n",
    "             linewidth=4.0)\n",
    "    plt.title(data_type + ' Normalized Residuals Histogram')\n",
    "    plt.xlabel('residual [-]')\n",
    "    plt.ylabel('density')\n",
    "    \n",
    "    # Q-Q plot\n",
    "    plt.subplot(122)\n",
    "    sc.stats.probplot(ehat_normalized, dist=\"norm\", plot=plt)\n",
    "    plt.title(data_type + ' Normalized Residuals Q-Q Plot')\n",
    "    plt.xlabel('Theoretical Quantiles')\n",
    "    plt.ylabel('Sample Quantiles') \n",
    "    \n",
    "    print (f'The mean value of the {data_type} residuals is {np.mean(ehat):.3f} m')\n",
    "    print (f'The standard deviation of the {data_type} residuals is {np.std(ehat):.3f} m')\n",
    "\n",
    "    return ehat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9b60f",
   "metadata": {
    "id": "80a9b60f"
   },
   "source": [
    "## Part 2: Set-up non-linear functional model\n",
    "\n",
    "In the model we fitted so far, we only considered a linear velocity and seasonal variation in groundwater level. However, in reality the response to groundwater injection is likely to be more complicated than just a linear uplift. Therefore you will now consider a slightly more sophisticated, non-linear model to account for the observed uplift. \n",
    "\n",
    "*Please note that this is very simplified model that does not necessarily rely on physics.* \n",
    "\n",
    "The model under null hypothesis $H_0$ is defined as:\n",
    "\n",
    "$$\n",
    "d = d_0 + v \\ (1-\\exp\\left(\\frac{-t}{a}\\right)) + A\\sin(\\frac{2\\pi t}{365} - \\phi),\n",
    "$$\n",
    "\n",
    "where $d$ is the displacement, and $t$ is the time, and $\\phi =\\frac{\\pi}{2}$. \n",
    "\n",
    "The model now has 4 unknowns:\n",
    "1. $d_0$, the initial displacement at $t_0$\n",
    "2. $v$, which can be seen as the response of the soil layers due to groundwater injection. \n",
    "3. $a$, a scaling parameter which represents the memory of the system\n",
    "4. $A$, amplitude of the seasonal effect\n",
    "\n",
    "It can be seen that the model is non-linear. We will therefore use non-linear least-squares to solve for the unknown parameters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653c958-0686-448f-8ecc-f21946db82bf",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "\n",
    "<b>Task 2.1: </b>   \n",
    "    \n",
    "Choose initial values for the model parameters. Use the code and Markdown cells below to justify your decision. We suggest two possible approaches: a) use the forward model and make a plot to see if you can get it in the right order of magnitude, or b) make an inference about what the values might be using knowledge about each term in the model.\n",
    "    \n",
    "<i>Note: it may be useful at this point to define a function for your forward model to check the values. You will be able to re-use it in later Tasks as well.<i>\n",
    "    \n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5bf67",
   "metadata": {
    "id": "3ba5bf67"
   },
   "outputs": [],
   "source": [
    "def forward_model(time, d_i, v_i, a_i, A_i):\n",
    "    \"\"\"Compute the displacements based on our initial guess.\n",
    "    \"\"\"\n",
    "\n",
    "    y_comp = d_i + v_i*(1-np.exp(-time/a_i)) + A_i * np.sin(2 * np.pi * time / 365 - np.pi/2)\n",
    "\n",
    "    return y_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8002fe",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#facb8e; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\"> <p>\n",
    "\n",
    "Note: In the code below we will create an interactive plot. Note that these do *not* work/render online. You have to download the notebook and run it locally to see the interactivity.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddf324-11fe-4516-a37c-b8a90ce84c18",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your initials guess\n",
    "v_i = ### YOUR CODE HERE ###\n",
    "a_i = ### YOUR CODE HERE ###\n",
    "do_i = ### YOUR CODE HERE ###\n",
    "A_i = ### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "v_slider = widgets.FloatSlider(value=v_i, min=0.0, max=1.0, step=0.01, description='v_i [m/day]:')\n",
    "a_slider = widgets.FloatSlider(value=a_i, min=0.0, max=150.0, step=1.0, description='a_i [°]:')\n",
    "do_slider = widgets.FloatSlider(value=do_i, min=9.8, max=10.2, step=0.01, description='d_o [m]:')\n",
    "A_slider = widgets.FloatSlider(value=A_i, min=-0.3, max=0.5, step=0.01, description='A_i [m]:')\n",
    "\n",
    "def update_plot(v_i, a_i, do_i, A_i):\n",
    "    y_init = forward_model(gnss_doy, do_i, v_i, a_i, A_i)\n",
    "    res = y_init - gnss_obs\n",
    "    res2 = np.sum(res**2)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(gnss_dates, y_init, 'r-', label='Initial guess')\n",
    "    plt.plot(gnss_dates, gnss_obs, 'co', mec='black', label='Observations')\n",
    "    plt.title('GNSS Observations and Initial Guess, Residual Sum of Squares: {:.4f} $m^2$'.format(res2))\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Displacement [m]')\n",
    "    plt.ylim(np.min(gnss_obs)-3*np.std(gnss_obs), np.max(gnss_obs)+3*np.std(gnss_obs))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interact(update_plot, v_i=v_slider, a_i=a_slider, do_i=do_slider, A_i=A_slider);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab614ad",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#choose your own initial values\n",
    "v_i = 0.35\n",
    "a_i = 80\n",
    "do_i = 10.099\n",
    "A_i = 0.05\n",
    "\n",
    "\n",
    "v_slider = widgets.FloatSlider(value=v_i, min=0.0, max=1.0, step=0.01, description='v_i [m/day]:')\n",
    "a_slider = widgets.FloatSlider(value=a_i, min=0.0, max=150.0, step=1.0, description='a_i [°]:')\n",
    "do_slider = widgets.FloatSlider(value=do_i, min=9.8, max=10.2, step=0.01, description='d_o [m]:')\n",
    "A_slider = widgets.FloatSlider(value=A_i, min=-0.3, max=0.5, step=0.01, description='A_i [m]:')\n",
    "\n",
    "def update_plot(v_i, a_i, do_i, A_i):\n",
    "    y_init = forward_model(gnss_doy, do_i, v_i, a_i, A_i)\n",
    "    res = y_init - gnss_obs\n",
    "    res2 = np.sum(res**2)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(gnss_dates, y_init, 'r-', label='Initial guess')\n",
    "    plt.plot(gnss_dates, gnss_obs, 'co', mec='black', label='Observations')\n",
    "    plt.title('GNSS Observations and Initial Guess, Residual Sum of Squares: {:.4f} $m^2$'.format(res2))\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Displacement [m]')\n",
    "    plt.ylim(np.min(gnss_obs)-3*np.std(gnss_obs), np.max(gnss_obs)+3*np.std(gnss_obs))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "interact(update_plot, v_i=v_slider, a_i=a_slider, do_i=do_slider, A_i=A_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef9883-3316-4102-9b83-c725ea0c2d2b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 2.1:</b> \n",
    "\n",
    "- For $d_0$ and $A$ you could use the estimated values from the linear model, but they do not work very well because their estimators are biased with the linear model.\n",
    "    \n",
    "- For $v$: realize that it is the difference between displacement at start and end of the observation interval (look at plot with data).\n",
    "    \n",
    "- For $a$: you could plot the curve with initial values and try different values of $a$ to see which one would fit the observations well here.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09f7d6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2.2: </b>   \n",
    "    \n",
    "Set up the Jacobian matrix for the non-linear least-squares. Using the initial values from Task 2.1, print the first 5 rows of the Jacobian matrix to confirm that your function works (i.e., confirm code runs, and initial values give acceptable results). \n",
    "\n",
    "**Please check the print statement from the cell below to see if you've set up your Jacobian correctly!**\n",
    "    \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef41e9",
   "metadata": {
    "id": "4aef41e9",
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "def jacobian(time, do_i, v_i, a_i, A_i):\n",
    "    \"\"\"Create the Jacobian matrix.\n",
    "    \n",
    "    The columns represent the linearized system of equations.\n",
    "    \"\"\"    \n",
    "    \n",
    "    J_c1 = ### YOUR CODE HERE ###\n",
    "    J_c2 = ### YOUR CODE HERE ###\n",
    "    J_c3 = ### YOUR CODE HERE ###\n",
    "    J_c4 = ### YOUR CODE HERE ###\n",
    "\n",
    "    J = np.column_stack((J_c1, J_c2, J_c3, J_c4))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12434f",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def jacobian(time, do_i, v_i, a_i, A_i):\n",
    "    \"\"\"Create the Jacobian matrix.\n",
    "    \n",
    "    The columns represent the linearized system of equations.\n",
    "    \"\"\"    \n",
    "\n",
    "    J_c1 = np.ones(len(time))\n",
    "    J_c2 = 1 - np.exp(-time/a_i)\n",
    "    J_c3 = -v_i*time/a_i**2 * np.exp(-time/a_i)\n",
    "    J_c4 = np.sin(2 * np.pi * time / 365 - np.pi/2)\n",
    "\n",
    "    J = np.column_stack((J_c1, J_c2, J_c3, J_c4))\n",
    "    \n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Jacobian function\n",
    "time_check = np.array([0, 100, 200])\n",
    "\n",
    "do_i_check = 1.0\n",
    "v_i_check = 2.0\n",
    "a_i_check = 50.0\n",
    "A_i_check = 0.5\n",
    "\n",
    "J_check = jacobian(time_check, do_i_check, v_i_check, a_i_check, A_i_check)\n",
    "\n",
    "J_expected = np.array([\n",
    "    [1.0, 0.0, -0.0, -1.0],\n",
    "    [1.0, 0.865, -0.011, 0.15],\n",
    "    [1.0, 0.982, -0.003, 0.955]\n",
    "])\n",
    "\n",
    "if np.allclose(J_check, J_expected, atol=1e-3):\n",
    "    print(\"✅ Jacobian matches the expected output!\")\n",
    "else:\n",
    "    print(\"❌ Jacobian does NOT match the expected output.\")\n",
    "    print(\"Computed J:\\n\", J_check)\n",
    "    print(\"Expected J:\\n\", J_expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f8dd4",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# Print first 5 rows of the Jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e5e26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1664699883678,
     "user": {
      "displayName": "C Yin",
      "userId": "14075875094781565898"
     },
     "user_tz": -120
    },
    "id": "c57e5e26",
    "outputId": "2b46920b-8ff3-47c5-cc03-8dad183d52b3",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "J = jacobian(gnss_doy, do_i, v_i, a_i, A_i)\n",
    "\n",
    "print ('The first 5 rows of the Jacobian matrix are:')\n",
    "print (J[0:5,:])\n",
    "\n",
    "n_2 = np.shape(J)[1]\n",
    "print(f'\\nThe number of unknowns is {n_2}')\n",
    "print(f'The redundancy (GNSS) is {m_gnss - n_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a640428",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 2.3:</b>   \n",
    "    \n",
    "What is the redundancy of the model with GNSS?\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193256db",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 2.3:</b> \n",
    "\n",
    "- The number of unknowns is 4\n",
    "- The redundancy (GNSS) is 361\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4633d84",
   "metadata": {
    "id": "b4633d84"
   },
   "source": [
    "## Part 3: Set-up Gauss-Newton iteration algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafd29d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.1: </b>   \n",
    "    \n",
    "Set up a Gauss-Newton iteration algorithm (complete the code below). Choose the criterion to stop the iteration. \n",
    "Explain below how and why you define the stop-criterium. \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FbsD75dR0w5b",
   "metadata": {
    "id": "FbsD75dR0w5b",
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "def nlsq_iteration(x0, day, y_obs, Sigma_Y):\n",
    "    \"\"\"Use Gauss-Newton iteration to find non-linear parameters.\"\"\"\n",
    "\n",
    "    xnrm = 1000 # initialize stop criteria\n",
    "\n",
    "    xhat_i = np.zeros((50, 4))\n",
    "    xhat_i[0,:] = x0\n",
    "\n",
    "    do_i = xhat_i[0,0]\n",
    "    v_i = xhat_i[0,1]\n",
    "    a_i = xhat_i[0,2]\n",
    "    A_i = xhat_i[0,3]   \n",
    "\n",
    "    iter_ind = 0\n",
    "\n",
    "    while xnrm >= 1e-12 and iter_ind < 49:\n",
    "\n",
    "        # computed deformation yi based on 'estimates' \n",
    "        y_i = forward_model(day, do_i, v_i, a_i, A_i)\n",
    "        \n",
    "        dy = ### YOUR CODE HERE ###\n",
    "        J = ### YOUR CODE HERE ###\n",
    "\n",
    "        d_xhat, Sigma_Xhat = ### YOUR CODE HERE ###\n",
    "        # Hint: re-use your function BLUE, above\n",
    "\n",
    "        xhat_i[iter_ind+1,:] = xhat_i[iter_ind,:] + d_xhat.T\n",
    "\n",
    "        do_i  = xhat_i[iter_ind+1,0]\n",
    "        v_i  = xhat_i[iter_ind+1,1]\n",
    "        a_i  = xhat_i[iter_ind+1,2]\n",
    "        A_i  = xhat_i[iter_ind+1,3]\n",
    "        \n",
    "        xnrm = ### YOUR CODE HERE ###\n",
    "\n",
    "        # Update the iteration number\n",
    "        iter_ind += 1\n",
    "\n",
    "        if iter_ind==49:\n",
    "            print(\"Number of iterations too large, check initial values.\")\n",
    "\n",
    "    xhat = xhat_i[iter_ind,:]\n",
    "    xhat_i = xhat_i[0:iter_ind+1, :]\n",
    "    return xhat, Sigma_Xhat, xhat_i, iter_ind, J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324756a1",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def nlsq_iteration(x0, day, y_obs, Sigma_Y):\n",
    "    \"\"\"Use Gauss-Newton iteration to find non-linear parameters.\"\"\"\n",
    "\n",
    "    xnrm = 1000 # initialize stop criteria\n",
    "\n",
    "    xhat_i = np.zeros((50, 4))\n",
    "    xhat_i[0,:] = x0\n",
    "\n",
    "    do_i = xhat_i[0,0]\n",
    "    v_i = xhat_i[0,1]\n",
    "    a_i = xhat_i[0,2]\n",
    "    A_i = xhat_i[0,3]   \n",
    "\n",
    "    iter_ind = 0\n",
    "\n",
    "    while xnrm >= 1e-12 and iter_ind < 49:\n",
    "\n",
    "        # computed deformation yi based on 'estimates' \n",
    "        y_i = forward_model(day, do_i, v_i, a_i, A_i)\n",
    "\n",
    "        dy = y_obs- y_i\n",
    "        J = jacobian(day, do_i, v_i, a_i, A_i)\n",
    "\n",
    "        d_xhat, Sigma_Xhat = BLUE(J, dy, Sigma_Y)\n",
    "\n",
    "        xhat_i[iter_ind+1,:] = xhat_i[iter_ind,:] + d_xhat.T\n",
    "\n",
    "        do_i  = xhat_i[iter_ind+1,0]\n",
    "        v_i  = xhat_i[iter_ind+1,1]\n",
    "        a_i  = xhat_i[iter_ind+1,2]\n",
    "        A_i  = xhat_i[iter_ind+1,3]\n",
    "        \n",
    "        xnrm = d_xhat.T @ np.linalg.inv(Sigma_Xhat) @ d_xhat\n",
    "\n",
    "        # Update the iteration number\n",
    "        iter_ind += 1\n",
    "\n",
    "        if iter_ind==49:\n",
    "            print(\"Number of iterations too large, check initial values.\")\n",
    "\n",
    "    xhat = xhat_i[iter_ind,:]\n",
    "    xhat_i = xhat_i[0:iter_ind+1, :]\n",
    "    return xhat, Sigma_Xhat, xhat_i, iter_ind, J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ca81c",
   "metadata": {
    "id": "588f31ef"
   },
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "\n",
    "<b>Solution 3.1:</b>\n",
    "\n",
    "We will use the 'weighted squared norm' of $\\Delta \\hat{\\mathrm{x}}_{[i]}$, with the inverse covariance matrix $\\Sigma_{\\hat{X}}^{-1}$ as the weight matrix. In this way we account for different precisions of the parameters (high precision means we want the deviation to be smaller), as well as different order of magnitudes of the parameters.\n",
    "</p>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eef3de",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.2: </b>   \n",
    "\n",
    "Apply Gauss–Newton iteration on your model (run the code you completed above).\n",
    "For each unknown parameter, plot your estimates versus the iteration number (horizontal axis: iteration number, vertical axis: parameter estimate).\n",
    "\n",
    "Choose an appropriate number of iterations to clearly demonstrate the convergence behavior of your estimates.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313380a0",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "x0 = [do_i, v_i, a_i, A_i]\n",
    "\n",
    "[xhat_gnss, Sigma_Xhat_gnss, xhat_i_gnss, niter_gnss, J_final_gnss] = nlsq_iteration(### YOUR CODE HERE ###)\n",
    "\n",
    "print('\\n GNSS Results for each iteration (#Iterations =', niter_gnss, ')')\n",
    "print(xhat_i_gnss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74680ab5",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "x0 = [do_i, v_i, a_i, A_i]\n",
    "\n",
    "[xhat_gnss, Sigma_Xhat_gnss, xhat_i_gnss, niter_gnss, J_final_gnss] = nlsq_iteration(x0, gnss_doy, y_gnss, Sigma_Y_gnss)\n",
    "\n",
    "print('\\n GNSS Results for each iteration (#Iterations =', niter_gnss, ')')\n",
    "print(xhat_i_gnss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b7aaa",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#facb8e; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\"> <p>\n",
    "\n",
    "Note: In the code below we will create an interactive plot. Note that these do *not* work/render online. You have to download the notebook and run it locally to see the interactivity.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52c8b9",
   "metadata": {
    "id": "7d52c8b9"
   },
   "outputs": [],
   "source": [
    "iteration_slider = widgets.IntSlider(value=0, min=0, max=niter_gnss, step=1, description='Iteration:')\n",
    "\n",
    "def plot_fit_iteration(iteration, xhat):\n",
    "    yhat = forward_model(gnss_doy, xhat[iteration,0], xhat[iteration,1], xhat[iteration,2], xhat[iteration,3])\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(gnss_dates, gnss_obs, 'co', mec='black', label='Observations')\n",
    "    print(yhat.shape)\n",
    "    plt.plot(gnss_dates, yhat, 'r-', label='Model')\n",
    "    plt.title('GNSS Observations and Model Fit')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Displacement [m]')\n",
    "    plt.ylim(np.min(gnss_obs)-3*np.std(gnss_obs), np.max(gnss_obs)+3*np.std(gnss_obs))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_parameters_iteration(iteration, xhat):    \n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.plot(xhat[:, 0], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 0], 'ro', markersize=12)\n",
    "    plt.title('Estimated offset')\n",
    "    plt.ylabel('Offset [m]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.plot(xhat[:, 1], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 1], 'ro', markersize=12)\n",
    "    plt.title('Estimated v value')\n",
    "    plt.ylabel('Estimated v value [m/year]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.plot(xhat[:, 2], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 2], 'ro', markersize=12)\n",
    "    plt.title('Estimated $a$ value')\n",
    "    plt.ylabel('a value [days]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.plot(xhat[:, 3], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 3], 'ro', markersize=12)\n",
    "    plt.title('Estimated A value')\n",
    "    plt.ylabel('A value [m]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OtSGy-5NfSP6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1664699886743,
     "user": {
      "displayName": "C Yin",
      "userId": "14075875094781565898"
     },
     "user_tz": -120
    },
    "id": "OtSGy-5NfSP6",
    "outputId": "e11f185d-7400-4ca8-8378-8f8464757f01"
   },
   "outputs": [],
   "source": [
    "interact(plot_fit_iteration, iteration=iteration_slider, xhat=fixed(xhat_i_gnss), yhat=forward_model(gnss_doy, xhat_i_gnss[iteration_slider.value,0], xhat_i_gnss[iteration_slider.value,1], xhat_i_gnss[iteration_slider.value,2], xhat_i_gnss[iteration_slider.value,3]));\n",
    "interact(plot_parameters_iteration, iteration=iteration_slider, xhat=fixed(xhat_i_gnss));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f063b5d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black;width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 3.3 </b>   \n",
    "    \n",
    "- Does your iteration converge? If not, find out why and provide an explanation.\n",
    "\n",
    "- After how many iterations does it converge? \n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a7debd",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 3.3:</b>  \n",
    "\n",
    "Convergence! 7 iterations.\n",
    "\n",
    "</p>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c40713",
   "metadata": {
    "id": "b9c40713"
   },
   "source": [
    "## Part 4: Assess the Precision of the Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1082035",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 4.1: </b>     \n",
    "    \n",
    "What is the quality of the final estimates? \n",
    "    \n",
    "Provide the full covariance matrix of your estimates, and give an interpretation of the numbers in the covariance matrix.\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46f3f3",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# ### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9e513",
   "metadata": {
    "id": "5af9e513",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def show_std(Sigma_Xhat, data_type):\n",
    "    print ('The standard deviation for',\n",
    "           data_type + '-offset is',\n",
    "           np.round(np.sqrt(Sigma_Xhat[0,0]),4), 'm')\n",
    "    print ('The standard deviation for',\n",
    "           data_type + '-velocity is',\n",
    "           np.round(np.sqrt(Sigma_Xhat[1,1]),4), 'm/day')\n",
    "    print ('The standard deviation for',\n",
    "           data_type + '-a is',\n",
    "           np.round(np.sqrt(Sigma_Xhat[2,2]),4), 'days')\n",
    "    print ('The standard deviation for',\n",
    "           data_type + '-amplitude is',\n",
    "           np.round(np.sqrt(Sigma_Xhat[3,3]),4), 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fJA-BwcchWga",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1664699887632,
     "user": {
      "displayName": "C Yin",
      "userId": "14075875094781565898"
     },
     "user_tz": -120
    },
    "id": "fJA-BwcchWga",
    "outputId": "9d8f20d6-c597-45ff-9c4b-8277f94bffef",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print ('\\nCovariance matrix of estimated parameters (GNSS):')\n",
    "print (Sigma_Xhat_gnss, '\\n')\n",
    "show_std(Sigma_Xhat_gnss, 'GNSS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80e21d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 4.1:</b> \n",
    "\n",
    "The quality of the estimated parameters is given by their Standard Deviations (Square roots of the diagonal elements of the covariance matrix) and the Covariances (off-diagonal elements). The off-diagonal elements (covariances) indicate correlation between the estimated parameters. A large covariance suggests the parameters are difficult to separate in the model.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21692a1a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 4.2:</b>   \n",
    "    \n",
    "Compute the modeled displacements ($\\hat{\\mathrm{y}}$), and corresponding residuals ($\\hat{\\mathrm{\\epsilon}}$). \n",
    "Visualize the results in two graphs and add the confidence bounds ($t$-versus-displacement and $t$-versus-residuals).\n",
    "\n",
    "Also create a histogram of the residuals where you plot the normal distribution (which you can estimate from the histogram) as well and report the mean and sigma of the residuals. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7da055",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "yhat_gnss_nonlinear = forward_model(### YOUR CODE HERE ###)\n",
    "ehat_gnss_nonlinear = plot_residual(### YOUR CODE HERE ###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ngZMBQM87QMr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1664699889284,
     "user": {
      "displayName": "C Yin",
      "userId": "14075875094781565898"
     },
     "user_tz": -120
    },
    "id": "ngZMBQM87QMr",
    "outputId": "35c44fc7-4b48-4727-c9cf-65c01e528d19",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "yhat_gnss_nonlinear = forward_model(gnss_doy, xhat_gnss[0], xhat_gnss[1], xhat_gnss[2], xhat_gnss[3])\n",
    "ehat_gnss_nonlinear = plot_residual(gnss_dates, y_gnss, yhat_gnss_nonlinear,\n",
    "                             'GNSS', J_final_gnss, Sigma_Xhat_gnss,\n",
    "                             Sigma_Y_gnss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3937085",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 4.3:</b>   \n",
    "\n",
    "Answer the following questions:\n",
    "<ol>\n",
    "    <li>Do you see any systematic effect?</li>\n",
    "    <li>Give your interpretation for any discrepancy between observations and the model?</li>\n",
    "    <li>What is the mean value of the residuals and what does this value tells you?</li>\n",
    "    <li>And what is the empirical standard deviation of the residuals? Is it as expected?</li>\n",
    "</ol>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a7604",
   "metadata": {
    "id": "588f31ef"
   },
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 4.4:</b> \n",
    "\n",
    "    \n",
    "The mean and standard deviations are as expected given the precision of 15 mm. However, a discontinuity can be observed in the residual plot around 2024-07, which may also explain the deviations in the upper tail of the residual distribution, as some residuals became larger than expected and the upper quantiles (outliers) no longer follow the expected distribution.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a7a99",
   "metadata": {},
   "source": [
    "##  Part 5: Model Testing\n",
    "You would now like to test the validity of your model using the overall model test, with a false alarm probability of 95%. Is the null hypothesis (default model is correct) accepted?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070198a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 5.1:</b>   \n",
    "\n",
    "Conduct the Overall Model Test (OMT) to evaluate the statistical consistency of your non-linear model. Calculate the test statistic ($T_{\\text{detection}}$) and determine the critical value ($T_{\\text{critical}}$) at a 95% confidence level, using the model redundancy ($r$) as the degrees of freedom. Report the calculated test statistic and state whether you accept or reject the nullhypothesis ($H_0$).\n",
    "\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f2341",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# Dimensions of design matrix\n",
    "m,n = ### ### YOUR CODE HERE ### ###\n",
    "\n",
    "# Compute redundancy\n",
    "r = ### ### YOUR CODE HERE ### ###\n",
    "\n",
    "# OMT test statistics\n",
    "t_detection = ### ### YOUR CODE HERE ### ###\n",
    "\n",
    "# OMT threshold\n",
    "T_detection = ### ### YOUR CODE HERE ### ###\n",
    "\n",
    "print(f'\\nTest statistic is {t_detection:.2f}, threshold is {T_detection:.2f}.') \n",
    "\n",
    "if ### YOUR CODE HERE ###:\n",
    "    print('We accept the null hypothesis H0')\n",
    "else:\n",
    "    print('We reject the null hypothesis H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5dbff",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "m,n = np.shape(J)\n",
    "r = m - n\n",
    "\n",
    "t_detection = ehat_gnss_nonlinear.T @ np.linalg.inv(Sigma_Y_gnss) @ ehat_gnss_nonlinear\n",
    "T_detection = chi2.ppf(0.95, r)\n",
    "\n",
    "print(f'\\nTest statistic is {t_detection:.2f}, threshold is {T_detection:.2f}.') \n",
    "if t_detection < T_detection:\n",
    "    print('We accept the null hypothesis H0')\n",
    "else:\n",
    "    print('We reject the null hypothesis H0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73576229",
   "metadata": {},
   "source": [
    "### Model under $H_a$\n",
    "\n",
    "As shown in the residual plot of the nonlinear model fitting, a shift may happen around 2024-07, which may explain the rejection of the null hypothesis. To test whether this is true and if so, to identify the epoch where the shift happens, you need to execute the Generalized Likelihood Ratio Test (GLRT). The following model under alternatives hypotheses $H_a$ needs to be considered, where the shift happens at $k$-th epoch, the observation equations under $H_a$ can be written as\n",
    "\n",
    "$$\n",
    "d = d_0 + v \\ (1-\\exp\\left(\\frac{-t}{a}\\right)) + A\\sin(\\frac{2\\pi t}{365} - \\phi),\\quad t<k \\\\\n",
    "d = d_0 + v \\ (1-\\exp\\left(\\frac{-t}{a}\\right)) + A\\sin(\\frac{2\\pi t}{365}- \\phi) + s,\\quad t>=k,\n",
    "$$\n",
    "where $s$ is the size of the shift.\n",
    "\n",
    "According to the observation equation under $H_a$, please update your functions to compute the forward model, Jacobian, and non-linear iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f0c12",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 5.2:</b>   \n",
    "\n",
    "Implement the updated forward model and construct the new $5 \\times 1$ Jacobian matrix $(\\mathbf{J})$ required for this system. Then, set up the Gauss-Newton iteration algorithm to solve for the five non-linear parameters. \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e25f1",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "def forward_model_with_shift(time, do_i, v_i, a_i, A_i, k, shift):\n",
    "    \n",
    "    \"\"\"Compute the displacements based on our initial guess.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_comp = do_i + v_i*(1-np.exp(-time/a_i)) + A_i * np.sin(2 * np.pi * time / 365 - np.pi/2)\n",
    "    y_shift = np.zeros(len(time))\n",
    "    y_shift[time>=k] = shift\n",
    "    y_comp = y_comp + y_shift\n",
    "    \n",
    "    return y_comp\n",
    "\n",
    "\n",
    "def jacobian_with_shift(time, do_i, v_i, a_i, A_i, k, shift):\n",
    "    \n",
    "    \"\"\"Create the Jacobian matrix.\n",
    "    \n",
    "    The columns represent the linearized system of equations.\n",
    "    \"\"\"    \n",
    "    J_c1 = ### YOUR CODE HERE ###\n",
    "    J_c2 = ### YOUR CODE HERE ###\n",
    "    J_c3 = ### YOUR CODE HERE ###\n",
    "    J_c4 = ### YOUR CODE HERE ###\n",
    "    J_c5 = ### YOUR CODE HERE ###\n",
    "    J_c5[time>=k] = ### YOUR CODE HERE ###\n",
    "\n",
    "    J = np.column_stack((J_c1, J_c2, J_c3, J_c4, J_c5))\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def nlsq_iteration_with_shift(x0, day, y_obs, Sigma_Y, k):\n",
    "    \"\"\"Use Gauss-Newton iteration to find non-linear parameters.\"\"\"\n",
    "\n",
    "    xnrm = 1000 # initialize stop criteria\n",
    "\n",
    "    xhat_i = np.zeros((50, 5))\n",
    "    xhat_i[0,:] = x0\n",
    "\n",
    "    do_i = xhat_i[0,0]\n",
    "    v_i = xhat_i[0,1]\n",
    "    a_i = xhat_i[0,2]\n",
    "    A_i = xhat_i[0,3]\n",
    "    shift_i = xhat_i[0,4]\n",
    "\n",
    "    iter_ind = 0\n",
    "\n",
    "    while xnrm >= 1e-12 and iter_ind < 49:\n",
    "\n",
    "        # computed deformation yi based on 'estimates' \n",
    "        y_i = forward_model_with_shift(day, do_i, v_i, a_i, A_i, k, shift_i)\n",
    "        \n",
    "        dy = ### YOUR CODE HERE ###\n",
    "        J = ### YOUR CODE HERE ###\n",
    "\n",
    "        d_xhat, Sigma_Xhat = ### YOUR CODE HERE ###\n",
    "        # Hint: re-use your function BLUE, above\n",
    "\n",
    "        xhat_i[iter_ind+1,:] = xhat_i[iter_ind,:] + d_xhat.T\n",
    "\n",
    "        do_i  = xhat_i[iter_ind+1,0]\n",
    "        v_i  = xhat_i[iter_ind+1,1]\n",
    "        a_i  = xhat_i[iter_ind+1,2]\n",
    "        A_i  = xhat_i[iter_ind+1,3]\n",
    "        shift_i = xhat_i[iter_ind+1,4]\n",
    "\n",
    "        xnrm = ### YOUR CODE HERE ###\n",
    "\n",
    "        # Update the iteration number\n",
    "        iter_ind += 1\n",
    "\n",
    "        if iter_ind==49:\n",
    "            print(\"Number of iterations too large, check initial values.\")\n",
    "\n",
    "    xhat = xhat_i[iter_ind,:]\n",
    "    xhat_i = xhat_i[0:iter_ind+1, :]\n",
    "    return xhat, Sigma_Xhat, xhat_i, iter_ind, J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad23693",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def forward_model_with_shift(time, do_i, v_i, a_i, A_i, k, shift):\n",
    "    \n",
    "    \"\"\"Compute the displacements based on our initial guess.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_comp = do_i + v_i*(1-np.exp(-time/a_i)) + A_i * np.sin(2 * np.pi * time / 365 - np.pi/2)\n",
    "    y_shift = np.zeros(len(time))\n",
    "    y_shift[time>=k] = shift\n",
    "    y_comp = y_comp + y_shift\n",
    "    \n",
    "    return y_comp\n",
    "\n",
    "\n",
    "def jacobian_with_shift(time, do_i, v_i, a_i, A_i, k, shift):\n",
    "    \n",
    "    \"\"\"Create the Jacobian matrix.\n",
    "    \n",
    "    The columns represent the linearized system of equations.\n",
    "    \"\"\"    \n",
    "    \n",
    "    J_c1 = np.ones(len(time))\n",
    "    J_c2 = 1 - np.exp(-time/a_i)\n",
    "    J_c3 = -v_i*time/a_i**2 * np.exp(-time/a_i)\n",
    "    J_c4 = np.sin(2 * np.pi * time / 365 - np.pi/2)\n",
    "    J_c5 = np.zeros(len(time))\n",
    "    J_c5[time>=k] = 1\n",
    "\n",
    "    J = np.column_stack((J_c1, J_c2, J_c3, J_c4, J_c5))\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def nlsq_iteration_with_shift(x0, day, y_obs, Sigma_Y, k):\n",
    "    \"\"\"Use Gauss-Newton iteration to find non-linear parameters.\"\"\"\n",
    "\n",
    "    xnrm = 1000 # initialize stop criteria\n",
    "\n",
    "    xhat_i = np.zeros((50, 5))\n",
    "    xhat_i[0,:] = x0\n",
    "\n",
    "    do_i = xhat_i[0,0]\n",
    "    v_i = xhat_i[0,1]\n",
    "    a_i = xhat_i[0,2]\n",
    "    A_i = xhat_i[0,3]\n",
    "    shift_i = xhat_i[0,4]\n",
    "\n",
    "    iter_ind = 0\n",
    "\n",
    "    while xnrm >= 1e-12 and iter_ind < 49:\n",
    "\n",
    "        # computed deformation yi based on 'estimates' \n",
    "        y_i = forward_model_with_shift(day, do_i, v_i, a_i, A_i, k, shift_i)\n",
    "        \n",
    "        dy = y_obs- y_i\n",
    "\n",
    "        J = jacobian_with_shift(day, do_i, v_i, a_i, A_i, k, shift_i)\n",
    "\n",
    "        d_xhat, Sigma_Xhat = BLUE(J, dy, Sigma_Y)\n",
    "\n",
    "        xhat_i[iter_ind+1,:] = xhat_i[iter_ind,:] + d_xhat.T\n",
    "\n",
    "        do_i  = xhat_i[iter_ind+1,0]\n",
    "        v_i  = xhat_i[iter_ind+1,1]\n",
    "        a_i  = xhat_i[iter_ind+1,2]\n",
    "        A_i  = xhat_i[iter_ind+1,3]\n",
    "        shift_i = xhat_i[iter_ind+1,4]\n",
    "\n",
    "        xnrm = d_xhat.T @ np.linalg.inv(Sigma_Xhat) @ d_xhat\n",
    "\n",
    "        # Update the iteration number\n",
    "        iter_ind += 1\n",
    "\n",
    "        if iter_ind==49:\n",
    "            print(\"Number of iterations too large, check initial values.\")\n",
    "\n",
    "    xhat = xhat_i[iter_ind,:]\n",
    "    xhat_i = xhat_i[0:iter_ind+1, :]\n",
    "    return xhat, Sigma_Xhat, xhat_i, iter_ind, J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84736f27",
   "metadata": {},
   "source": [
    "## Part 6: Model identification with GLRT\n",
    "\n",
    "You know that the shift happens at the days in the range $195$ to $204$, which means you have 10 alternative hypotheses with $195\\leq k<=204$. Compute the test statistics of the Generalized Likelihood Ratio Test (GLRT) for each alternative hypothesis. Then find the day of shift by identifying the most likely alternative hypothesis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfd1c6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 6.1:</b>   \n",
    "\n",
    "Utilize the Generalized Likelihood Ratio Test (GLRT) to estimate the most likely day the shift occurred, knowing $k$ is between day 195 and 204. For each possible day $k$, run the Gauss-Newton algorithm and compute the GLRT test statistic, which measures the improvement over the no-shift model. Finally, identify the day $\\mathbf{k}_{\\text{hat}}$ corresponding to the maximum test statistic and report this estimated day of shift.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0b71f",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "x0 = [do_i, v_i, a_i, A_i, 0]\n",
    "\n",
    "T_GLRT = np.zeros(10)\n",
    "for k in range(195,205):\n",
    "\n",
    "    [xhat_k, Sigma_Xhat_k, xhat_i_k, niter_k, J_final_k] = nlsq_iteration_with_shift(### YOUR CODE HERE ###)\n",
    "\n",
    "    yhat_gnss_k = ### YOUR CODE HERE ###\n",
    "\n",
    "    ehat_gnss_k = ### YOUR CODE HERE ###\n",
    "    \n",
    "    t_GLRT = t_detection - ehat_gnss_k.T @ np.linalg.inv(Sigma_Y_gnss) @ ehat_gnss_k\n",
    "    T_GLRT[k-195] = t_GLRT\n",
    "    \n",
    "i_GLRT = np.argmax(T_GLRT)\n",
    "k_hat = i_GLRT + 195\n",
    "\n",
    "print('\\nGLRT Test Statistics for each assumed change point k:')\n",
    "print(T_GLRT)\n",
    "print(f'\\nThe estimated time of the shift is day {k_hat}, with test statistic {T_GLRT[i_GLRT]:.2f}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99711791",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "x0 = [do_i, v_i, a_i, A_i, 0]\n",
    "\n",
    "T_GLRT = np.zeros(10)\n",
    "for k in range(195,205):\n",
    "\n",
    "    [xhat_k, Sigma_Xhat_k, xhat_i_k, niter_k, J_final_k] = nlsq_iteration_with_shift(x0, gnss_doy, y_gnss, Sigma_Y_gnss, k)\n",
    "\n",
    "    yhat_gnss_k = forward_model_with_shift(gnss_doy, xhat_k[0], xhat_k[1], xhat_k[2], xhat_k[3], k, xhat_k[4])\n",
    "\n",
    "    ehat_gnss_k = y_gnss - yhat_gnss_k\n",
    "    \n",
    "    t_GLRT = t_detection - ehat_gnss_k.T @ np.linalg.inv(Sigma_Y_gnss) @ ehat_gnss_k\n",
    "    T_GLRT[k-195] = t_GLRT\n",
    "    \n",
    "i_GLRT = np.argmax(T_GLRT)\n",
    "k_hat = i_GLRT + 195\n",
    "\n",
    "print('\\nGLRT Test Statistics for each assumed change point k:')\n",
    "print(T_GLRT)\n",
    "print(f'\\nThe estimated time of the shift is day {k_hat}, with test statistic {T_GLRT[i_GLRT]:.2f}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974f94a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 6.1:</b> \n",
    "\n",
    "    \n",
    "The estimated time of the shift is day 199, with test statistic 102.70.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21fca2",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 6.2:</b>   \n",
    "\n",
    "Plot the fitted model and the residuals of the selected alternative hypothesis. \n",
    "\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acc741",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "[xhat_k, Sigma_Xhat_k, xhat_i_k, niter_k, J_final_k] = nlsq_iteration_with_shift(### YOUR CODE HERE ###)\n",
    "\n",
    "yhat_gnss_k = forward_model_with_shift(### YOUR CODE HERE ###)\n",
    "ehat_gnss_k = plot_residual(gnss_dates, y_gnss, yhat_gnss_k,\n",
    "                             'GNSS', J_final_k, Sigma_Xhat_k,\n",
    "                             Sigma_Y_gnss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df005c1",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "[xhat_k, Sigma_Xhat_k, xhat_i_k, niter_k, J_final_k] = nlsq_iteration_with_shift(x0, gnss_doy, y_gnss, Sigma_Y_gnss, k_hat)\n",
    "\n",
    "yhat_gnss_k = forward_model_with_shift(gnss_doy, xhat_k[0], xhat_k[1], xhat_k[2], xhat_k[3], k=k_hat, shift=xhat_k[4])\n",
    "ehat_gnss_k = plot_residual(gnss_dates, y_gnss, yhat_gnss_k,\n",
    "                             'GNSS', J_final_k, Sigma_Xhat_k,\n",
    "                             Sigma_Y_gnss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74bb2b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#facb8e; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\"> <p>\n",
    "\n",
    "Note: In the code below we will create an interactive plot. Note that these do *not* work/render online. You have to download the notebook and run it locally to see the interactivity.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5878659",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_slider = widgets.IntSlider(value=0, min=0, max=niter_k, step=1, description='Iteration:')\n",
    "\n",
    "def plot_fit_iteration_2(iteration, xhat):\n",
    "    yhat = forward_model_with_shift(gnss_doy, xhat[iteration,0], xhat[iteration,1], xhat[iteration,2], xhat[iteration,3], k_hat, xhat[iteration,4])\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(gnss_dates, gnss_obs, 'co', mec='black', label='Observations')\n",
    "    print(yhat.shape)\n",
    "    plt.plot(gnss_dates, yhat, 'r-', label='Model')\n",
    "    plt.title('GNSS Observations and Model Fit')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Displacement [m]')\n",
    "    plt.ylim(np.min(gnss_obs)-3*np.std(gnss_obs), np.max(gnss_obs)+3*np.std(gnss_obs))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_parameters_iteration_2(iteration, xhat):    \n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.plot(xhat[:, 0], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 0], 'ro', markersize=12)\n",
    "    plt.title('Estimated offset')\n",
    "    plt.ylabel('Offset [m]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.plot(xhat[:, 1], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 1], 'ro', markersize=12)\n",
    "    plt.title('Estimated v value')\n",
    "    plt.ylabel('Estimated v value [m/year]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.plot(xhat[:, 2], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 2], 'ro', markersize=12)\n",
    "    plt.title('Estimated $a$ value')\n",
    "    plt.ylabel('a value [days]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.plot(xhat[:, 3], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 3], 'ro', markersize=12)\n",
    "    plt.title('Estimated A value')\n",
    "    plt.ylabel('A value [m]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.plot(xhat[:, 4], linewidth=4)\n",
    "    plt.plot(iteration, xhat[iteration, 4], 'ro', markersize=12)\n",
    "    plt.title('Estimated shift value')\n",
    "    plt.ylabel('Shift value [m]')\n",
    "    plt.xlabel('Number of iterations [-]')\n",
    "    plt.grid()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_fit_iteration_2, iteration=iteration_slider, xhat=fixed(xhat_i_k));\n",
    "interact(plot_parameters_iteration_2, iteration=iteration_slider, xhat=fixed(xhat_i_k));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9e02f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 6.3:</b>   \n",
    "\n",
    "Assumme a new null hypothesis ($H_{0_{shift}}$) that the shift you just calculated is included in the model. \n",
    "Rerun the Overall Model Test (OMT) using the parameters estimated with the optimal shift day, $\\mathbf{k}_{\\text{hat}}$, identified. Report the new test statistic value. Based on the comparison with the critical value, state whether you accept or reject the Null Hypothesis ($H_0$) and briefly explain what this result indicates about the final model's validity.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074c8b1",
   "metadata": {
    "tags": [
     "assignment"
    ]
   },
   "outputs": [],
   "source": [
    "# Dimensions of design matrix\n",
    "m,n = ### YOUR CODE HERE ###\n",
    "\n",
    "# Compute redundancy\n",
    "r = ### YOUR CODE HERE ###\n",
    "\n",
    "# OMT test statistics\n",
    "t_detection = ### YOUR CODE HERE ###\n",
    "\n",
    "# OMT threshold\n",
    "T_detection = ### YOUR CODE HERE ###\n",
    "\n",
    "print(f'\\nTest statistic is {t_detection:.2f}, threshold is {T_detection:.2f}.') \n",
    "if ### YOUR CODE HERE ###:\n",
    "    print('We accept the null hypothesis H0')\n",
    "else:\n",
    "    print('We reject the null hypothesis H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e610d",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "m,n = np.shape(J_final_k)\n",
    "r = m - n\n",
    "\n",
    "t_detection_shift = ehat_gnss_k.T @ np.linalg.inv(Sigma_Y_gnss) @ ehat_gnss_k\n",
    "T_detection_shift = chi2.ppf(0.95, r)\n",
    "print(f'\\nTest statistic is {t_detection_shift:.2f}, threshold is {T_detection_shift:.2f}.') \n",
    "if t_detection_shift < T_detection_shift:\n",
    "    print('We accept the null hypothesis H0_with_shift')\n",
    "else:\n",
    "    print('We accept the null hypothesis H0_with_shift')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e96c3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 6.3:</b> \n",
    "\n",
    "Test statistic is 337.76, threshold is 405.24. We accept the new model (with shift)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706dbcdd",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 6.4:</b>   \n",
    "\n",
    "Compare the final, selected model (with shift $s$ at day $\\mathbf{k}_{\\text{hat}}$), $H_{0_{shift}}$ against the initial model under $H_0$ (the model without shift) in terms of overall model fit and residual statistics. Explain in detail why it is essential to rely on the statistical tests (like the $\\chi^2$ and GLRT) rather than solely on visual inspection, especially when the simpler $H_0$ model might appear \"good enough\" when simply plotted against the observations.\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ac314",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 6.4:</b> \n",
    "\n",
    "- Less residuals are outside the confidence interval.\n",
    "- Residual has smaller standard deviation, distribution fits normal distribution\n",
    "- The value of the estimated $a$ changes from around 130 to 93, which shows how the mismodelling can affect the parameter estimation. This can be very important in case the model is used for predicting the displacements for the future!\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654bb50",
   "metadata": {
    "id": "8654bb50"
   },
   "source": [
    "## Task 7: Strategies to improve?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70973d0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AABAB2; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Task 7.1:</b>   \n",
    "\n",
    "In order to get a better fit to the data (smaller residuals) for this case study, which of the following strategies could help? (elaborate on your answer)\n",
    "<ol>\n",
    "    <li>better observations?</li>\n",
    "    <li>a more complicated geophysical model?</li>\n",
    "    <li>better initial values?</li>\n",
    "    <li>more observations?</li>\n",
    "</ol>\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f513402",
   "metadata": {
    "id": "588f31ef"
   },
   "source": [
    "<div style=\"background-color:#FAE99E; color: black; width:90%; vertical-align: middle; padding:15px; margin: 10px; border-radius: 10px\">\n",
    "<p>\n",
    "<b>Solution 7.1:</b> \n",
    "<ol>\n",
    "    <li>better observations will help, and should result in smaller residuals.</li>\n",
    "    <li>a more complicated geophysical model will help if it is able to capture the signal. However, since we don't see any systematic effects in the InSAR residuals, it is not expected that much gain can be expected. Including more parameters in the model will help to get smaller residuals, but is there still a geophysical explanation...?</li>\n",
    "    <li>better initial values won't help, since solution converged to valid results.</li>\n",
    "    <li>more observations generally helps, as long as they are not corrupted by outliers or systematic effects.</li>\n",
    "</ol> \n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07781b5e-6b4c-4b7b-a41c-09d1c1450465",
   "metadata": {},
   "source": [
    "> By Chengyu Yin, Lina Hagenah and Sandra Verhagen, Delft University of Technology. CC BY 4.0, more info on the Credits page of Workbook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
